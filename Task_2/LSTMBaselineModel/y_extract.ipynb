{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "# import torchtext.vocab as vocab\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"y_test.pkl\",'rb') as file1:\n",
    "    y_test_pkl = pickle.load(file1)\n",
    "with open(\"y_train.pkl\",'rb') as file2:\n",
    "    y_train_pkl = pickle.load(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1lines [00:00, 8701.88lines/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 3,  6,  7,  5,  4, 10,  8,  9,  2]), [3, 6, 7, 5, 4, 10, 8, 9, 2])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"<SOS> hello i am a person named nikhil <EOS>\"\n",
    "words = sent.split()\n",
    "vocab = build_vocab_from_iterator([words])\n",
    "indices = [vocab[word] for word in words]\n",
    "tensor = torch.tensor(indices)\n",
    "tensor,indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[\"<SOS>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46294,)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pkl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1lines [00:00,  9.75lines/s]\n"
     ]
    }
   ],
   "source": [
    "all_words = [word for sentence in y_train_pkl for word in sentence.split()]+[\"<EOS>\",\"<SOS>\"]\n",
    "vocab = build_vocab_from_iterator([all_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22210, 100434, 11428, 14541, 3, 1)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[\"yo\"],vocab[\"hella\"],vocab[\"hey\"],vocab[\"disappointing\"],vocab[\"the\"],vocab.stoi[\"<pad>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<unk>',\n",
       " '<pad>',\n",
       " '<hyperlink>',\n",
       " 'the',\n",
       " 'is',\n",
       " 'Valley',\n",
       " '<EOS>',\n",
       " '\\U000e0074\\U000e007f#FIFAWWC')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.itos[0],vocab.itos[1],vocab.itos[2],vocab.itos[3],vocab.itos[12],vocab.itos[6200],vocab.itos[64046],vocab.itos[118767]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Size of vocab: ', 118768)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Size of vocab: \", len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([65]),\n",
       " tensor([64047,     6,     6,     6,     6,     6,  2195,     3, 21020,  4812,\n",
       "            11,     3,   843,     5,    40,  2701,   106,  1040,  1333,  5000,\n",
       "          5326,     2, 64046,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1]),\n",
       " torch.Size([65]))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_arr = []\n",
    "for sentence in y_train_pkl:\n",
    "    sent = \"<SOS> \" + sentence + \" <EOS>\"\n",
    "    words = sent.split()\n",
    "    indices = [vocab[word] for word in words]\n",
    "    indices = indices + [1]*(65-len(indices))\n",
    "    tensor = torch.tensor(indices)\n",
    "    y_train_arr.append(tensor)\n",
    "\n",
    "y_train_arr[0].shape,y_train_arr[0],max(y_train_arr, key=lambda x: len(x)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.stack(y_train_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(y_train,\"y_train.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([65]),\n",
       " tensor([ 64047,     49,     19,   2781,      4,    779,      3,   8588,      8,\n",
       "              6,     28,  33738,      8,      3,   9865,     16,      6,     28,\n",
       "              8,   3437,    216,    252,   2810,   5740,  11026,     37, 112806,\n",
       "              7,     30,   4602,    706,     16,      0,    922,     17,      0,\n",
       "              0,      5,    251,     13,      0,    117,     27,    246,      2,\n",
       "              2,  64046,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1]),\n",
       " torch.Size([65]))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_arr = []\n",
    "for sentence in y_test_pkl:\n",
    "    sent = \"<SOS> \" + sentence + \" <EOS>\"\n",
    "    words = sent.split()\n",
    "    indices = [vocab[word] for word in words]\n",
    "    indices = indices + [1]*(65-len(indices))\n",
    "    tensor = torch.tensor(indices)\n",
    "    y_test_arr.append(tensor)\n",
    "\n",
    "y_test_arr[0].shape,y_test_arr[0],max(y_test_arr, key=lambda x: len(x)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = torch.stack(y_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(y_test,\"y_test.pt\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ff1e3bcc722a39238b6a7f93d00740f2997fe4fe04527d6796cad45df3c0deb"
  },
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit ('mne': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}